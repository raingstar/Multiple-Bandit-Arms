# Multiple-Bandit-Arms
Inspired by the book [Bandit Algorithms for Website Optimization](http://shop.oreilly.com/product/0636920027393.do), I extend the code to multiple bandit pproblem (select k arms out of N total arms at each step) as well as batch update process (reward is observed at a batch size of m). Thompson method is also introduced. 
Simulation result prefers Thompson Sampling among others. 
